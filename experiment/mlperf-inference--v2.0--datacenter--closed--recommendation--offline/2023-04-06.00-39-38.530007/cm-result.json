[
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 1725730,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4c94b8e309e44a84",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 1725730,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7a94116cf2024983",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_Triton",
    "Result": 1136270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9da7eb2f9b7e411e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_Triton",
    "Result": 1136270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "47299360278a41d7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT",
    "Result": 1105550,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "92b96385758c4046",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT",
    "Result": 1105550,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e824d51a48f946b5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 40424,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "89d2b34da2f64ec0",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 40424,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8b90d392dcaa4a04",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_Triton",
    "Result": 2446270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "bb2b8df9c9874b53",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_Triton",
    "Result": 2446270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "edd25003a0034cfb",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A2x2_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A2x2_TRT",
    "Result": 44256.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-1114S-WTRT (2x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7232P 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "87ef87304dcc49b9",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A2x2_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A2x2_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A2x2_TRT",
    "Result": 44256.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-1114S-WTRT (2x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7232P 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "571b3eb0877b48f1",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A2x2_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 2465750,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a7df8d14b44c476b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 2465750,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "560c0cbc4ab24235",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 2499040,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ce10afc5e8b54570",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 2499040,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "588738074b62459d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT",
    "Result": 35831.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3ba63de5f2734b9f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT",
    "Result": 35831.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "85a40c95a26c40e7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT_Triton",
    "Result": 1113970,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fbb2a6d423634f31",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT_Triton",
    "Result": 1113970,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "97a1e85c34424653",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "Result": 37579.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3efd86ed079245b7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "Result": 37579.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a93253d1ad124086",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT_HeteroMultiUse",
    "Result": 33319.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "98e3af04a5ed40c5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT_HeteroMultiUse",
    "Result": 33319.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c1c2f58d6fb24c39",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 2313280,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8b959f96f3174f96",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 2313280,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d701dbb7189844a5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT",
    "Result": 2477270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "847fb6e823ff4280",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT",
    "Result": 2477270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f8f69cfb05e44de6",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "Result": 1065600,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8ddd485348954fd3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "Result": 1065600,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5391eca0b36e4eae",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton",
    "Result": 1071130,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "40852c19998243ab",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton",
    "Result": 1071130,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d895f060bbc14583",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.173,
    "Accuracy_div_100": 0.80173,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT",
    "Result": 1125130,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "64240f20e66244e5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.173,
    "Accuracy_div_100": 0.80173,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT",
    "Result": 1125130,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "08c68c947f494ad3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 79.987,
    "Accuracy_div_100": 0.79987,
    "Availability": "rdi",
    "Division": "closed",
    "Location": "closed/Neuchips/results/Neuchips-triple-RecAccel/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Neuchips",
    "Platform": "Neuchips-triple-RecAccel",
    "Result": 4200.67,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "RecAccel",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Neuchips RecAccel",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel Core i9-10980XE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Terasic DE-10 Pro FPGA Acceleration Board",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 16.04.7 LTS",
    "uid": "79c69bdaeae54c8c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Neuchips/results/Neuchips-triple-RecAccel/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2460M1_A30x2_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Fujitsu",
    "Platform": "GX2460M1_A30x2_TRT",
    "Result": 270103,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2460M1 (2x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7302",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2 LTS",
    "uid": "063cc357416f45d3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2460M1_A30x2_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2460M1_A30x2_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2460M1_A30x2_TRT",
    "Result": 270103,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2460M1 (2x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7302",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2 LTS",
    "uid": "ad5276c381154bee",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2460M1_A30x2_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT",
    "Result": 2415820,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "7aadfd402a684d16",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT",
    "Result": 2415820,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "2dffb3cbe79d4c21",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_T4x1_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "XE2420_T4x1_TRT",
    "Result": 30883.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x T4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 22,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6238 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ECC on",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2.2004",
    "uid": "2c41df716c604d61",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_T4x1_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_T4x1_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "XE2420_T4x1_TRT",
    "Result": 30883.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x T4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 22,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6238 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ECC on",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2.2004",
    "uid": "edcbceb91ba44a9a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_T4x1_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT",
    "Result": 22022.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "13cfd15efdcf4e1b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT",
    "Result": 22022.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "78c3eb0b00db4c14",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 1166200,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "012f68da8ec448ac",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 1166200,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "1473967cfde44e04",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5688M6_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Inspur",
    "Platform": "NF5688M6_A100-SXM-80GBx8_TRT",
    "Result": 2605670,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5688M6 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8c9c4062252e4fb7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5688M6_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5688M6_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Inspur",
    "Platform": "NF5688M6_A100-SXM-80GBx8_TRT",
    "Result": 2605670,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5688M6 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "0979dbd0dd8d4836",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5688M6_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Inspur",
    "Platform": "NF5488A5_A100-SXM-80GBx8_TRT",
    "Result": 2645980,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5488A5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "ad9947a2b4d64900",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Inspur",
    "Platform": "NF5488A5_A100-SXM-80GBx8_TRT",
    "Result": 2645980,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5488A5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "3a850da630ef4b95",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 1428970,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "5174914e45f24325",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 1428970,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "cff2d258a16e4be8",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "R5500G5_A100-SXM-80GBx8_TRT",
    "Result": 2466690,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "400W_A100-SXM-80GB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8a8dbf01020f471d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "R5500G5_A100-SXM-80GBx8_TRT",
    "Result": 2466690,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "400W_A100-SXM-80GB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "fd94b46ca1f64e0e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT_Triton",
    "Result": 1112790,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "57ac7d89777f40e6",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT_Triton",
    "Result": 1112790,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "b78fbae6f9164fcb",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT",
    "Result": 1084020,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "2ca3eff91f7c473e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT",
    "Result": 1084020,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "bffb1260077a40c1",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  }
]

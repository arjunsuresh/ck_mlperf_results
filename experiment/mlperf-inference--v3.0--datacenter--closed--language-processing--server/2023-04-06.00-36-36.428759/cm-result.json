[
  {
    "Accuracy": 90.11113134712532,
    "Accuracy_div_100": 0.90111,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/dyson/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "dyson",
    "Result": 3429.65,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019)",
    "uid": "f4b527e2262f4ab6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Krai/results/dyson/bert-99/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT",
    "Result": 17399.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-741GE-TNRT (4xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "a3af64c72db74971",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT",
    "Result": 15198.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-741GE-TNRT (4xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "4b6f2cf86cf94a8a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT",
    "Result": 8602.68,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-221HE-FTNR (2xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "b578cdc3424b45a7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.9724610974641,
    "Accuracy_div_100": 0.90972,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT",
    "Result": 7803.08,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-221HE-FTNR (2xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "72d4e570e0364f0f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT",
    "Result": 32004.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9174F 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "6529310b90f9482e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.99810855108548,
    "Accuracy_div_100": 0.90998,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT",
    "Result": 28506.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9174F 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "10d2a873ca6b4a1e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 4701.69,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6cc44b2134cc43af",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 4001.83,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0f7e405021094d8e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 18001.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3c06be06ef7a47ae",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 9502.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "23d4d74650834c21",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 898.869,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b99d302a42f64118",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/L4x1_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.98410271283765,
    "Accuracy_div_100": 0.90984,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 529.892,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "667c4c0022cb4ae5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/L4x1_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 36808.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a0c6d6b1f06d432f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.98476529755553,
    "Accuracy_div_100": 0.90985,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 32004.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a1557443c46d4674",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 22407.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9d21655652c64399",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 11205.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f6d8d6bd94bf42f2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 25403.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9ae04bbe88614891",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 12817.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8731476eb15443b1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 59597.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "041df8156699474d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97909978622201,
    "Accuracy_div_100": 0.90979,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 49601.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0b355efa662044aa",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 7503.01,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0b05ce3d07a84aa8",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.98002968781414,
    "Accuracy_div_100": 0.9098,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 6352.47,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "cd653034622140dc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 23007.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "30a53c1b931b45cd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 10800.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d6beaaf6ce8d4e7d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 7442.91,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUS ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f6b56a4260e0412f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88622442251393,
    "Accuracy_div_100": 0.90886,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 3342.93,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUS ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "efaa8c2a2a214229",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 36006.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000-E12 (8xH100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "11dda3364efb402d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT_Triton",
    "Result": 11000.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "b09a71b8b7754594",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT_Triton",
    "Result": 5602.54,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "e40cb49352db48bc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_MIG_1g_10gb_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_MIG_1g_10gb_TRT",
    "Result": 329.79,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "16c20751ecfe42cd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_MIG_1g_10gb_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.884005578455,
    "Accuracy_div_100": 0.90884,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_MIG_1g_10gb_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_MIG_1g_10gb_TRT",
    "Result": 159.898,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "9091d12873424d8c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_MIG_1g_10gb_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 11598.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "588134b2062546d3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 5602.54,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "dd33c8d7964542c2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 24305,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo ThinkSystem SR670 V2 Server with 8x 80GB PCIe A100",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "NGC MLPerf v3.0.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Air Cooling",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "48610e483eb647b3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 11798.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo ThinkSystem SR670 V2 Server with 8x 80GB PCIe A100",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "NGC MLPerf v3.0.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Air Cooling",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "8f8c7bae86354ff2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8-qaic-v1.8.3.7-aic100",
    "Result": 5826.73,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "a770ad8332624c40",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/r282_z93_q8-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8-qaic-v1.8.3.7-aic100",
    "Result": 2923.89,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "26b429d599ed40cc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/r282_z93_q8-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16-qaic-v1.8.3.7-aic100",
    "Result": 11998.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "f1bedfc235034e38",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q16-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16-qaic-v1.8.3.7-aic100",
    "Result": 6102.61,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "0350b27def644b7e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q16-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 13497.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "39fc3d0a5b0d4360",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 6853.57,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "b105a109677f4d09",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.35055794377122,
    "Accuracy_div_100": 0.90351,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT_Triton/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT_Triton",
    "Result": 39807.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Triton 2.30.0 , CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "187c883db5df4717",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT_Triton/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.27830351985519,
    "Accuracy_div_100": 0.90278,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_T4x1_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE2420_T4x1_TRT",
    "Result": 289.815,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE2420 (1x T4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 22,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6238 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ECC on",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2.2004",
    "uid": "8730efff8daa4412",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE2420_T4x1_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR4520c_A30x1_TRT_DATACENTER",
    "Result": 1497.65,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR4520c (1x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b993647b47174960",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XR4520c_A30x1_TRT_DATACENTER",
    "Result": 678.917,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR4520c (1x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "277f3af7bc714cce",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 15497.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "2c467d1a01504048",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.99648516398608,
    "Accuracy_div_100": 0.90996,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 15397.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "57a312ab6d4e41d7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "vXE8545_A100_SXM_80GBx4_TRT",
    "Result": 13497.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545, VMware vSphere 8.0.1 (4x A100-SXM-80C, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80C",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "VMware vSphere 8.0.1, Ubuntu 20.04.2",
    "uid": "b4054caa931441fb",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "vXE8545_A100_SXM_80GBx4_TRT",
    "Result": 7004.02,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545, VMware vSphere 8.0.1 (4x A100-SXM-80C, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80C",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "VMware vSphere 8.0.1, Ubuntu 20.04.2",
    "uid": "32d62583aa254ba3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM4_80GBx4_TRT",
    "Result": 13597.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "3b222d60a0ec46a1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM4_80GBx4_TRT",
    "Result": 7004.02,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b28ecffb30904178",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 55999.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "4ce24c7e2a1542a2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97517645211892,
    "Accuracy_div_100": 0.90975,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 49500.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "84e4aad8b1f343b3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 11699,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "74bdcfd9d65c4ad9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 5851.66,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "cbc7c0616d7c4600",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM4_80GBx8_TRT",
    "Result": 27507.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "2bfd1119f5f2444a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM4_80GBx8_TRT",
    "Result": 13997.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "0cc78038ad8240f3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1098.37,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 224,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "36aa0c6c469b4a29",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 14897.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "47c09ea593c7499c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 6263.03,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1fde2066a1ca4314",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 15998,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8de6142da0674d21",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 6954.57,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "13646819865a4947",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 11848.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1e35b529f4bb4803",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 5401.64,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "dc1662c65ad54fb9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 5502.25,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2b77e02aaa8f40c8",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.98991310612459,
    "Accuracy_div_100": 0.9099,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 3600.34,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6715f755d1db4ebb",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 20995.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6aee5c70848249a3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 9102.69,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d5408b0627bc49e4",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "GIGABYTE",
    "Platform": "GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT",
    "Result": 36808.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G493-SB0",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6da6cb301c104324",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.93577472066417,
    "Accuracy_div_100": 0.90936,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "GIGABYTE",
    "Platform": "GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT",
    "Result": 30405.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G493-SB0",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "766819c6df8a4d06",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1103.29,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "CentOS Stream 8",
    "uid": "93206e59314542f9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G40_TRT",
    "Result": 17349.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "0a41e70910bf4da8",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87300540555174,
    "Accuracy_div_100": 0.90873,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G40_TRT",
    "Result": 7653,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "49808d99f4364de0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G50_TRT",
    "Result": 4711.64,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "ca3bee9ecaa04ca0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G50_TRT",
    "Result": 2108.18,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "989fbf34fa6d47fc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G50_TRT",
    "Result": 11399.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "8cc154fe96d04d8c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G50_TRT",
    "Result": 5051.58,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "05db54a6ef4e4e28",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G40_TRT",
    "Result": 7283.92,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "012e96caa0d94fa0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.9616803645096,
    "Accuracy_div_100": 0.90962,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G40_TRT",
    "Result": 4802.16,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "5232bdad31f1433e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G40_TRT",
    "Result": 6352.47,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "802501fab8704540",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88921457747342,
    "Accuracy_div_100": 0.90889,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G40_TRT",
    "Result": 2829.06,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "bd1c35b61e44418c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G50_TRT",
    "Result": 6302.66,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "66f633ce437b43dc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87300540555174,
    "Accuracy_div_100": 0.90873,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G50_TRT",
    "Result": 2848.84,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "1d2b6ad16df6456f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G40_TRT",
    "Result": 12078.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "bfc5a087a6df4f1c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G40_TRT",
    "Result": 5411.73,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "6475e6a87d794fe9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A30x3_Custom_X620_G40_TRT",
    "Result": 4502.22,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "2240ff34c55c402f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x3_Custom_X620_G40_TRT",
    "Result": 1998.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "8c845c53e70c4349",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L4x4_Custom_X620_G40_TRT",
    "Result": 3600.34,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (4x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "57b5ace6a68c4946",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.0017940132214,
    "Accuracy_div_100": 0.91002,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x4_Custom_X620_G40_TRT",
    "Result": 2198.24,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (4x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "0a3327b65f3449c4",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A30x4_Custom_X620_G50_TRT",
    "Result": 5701.99,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "a56cab8f447148c2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x4_Custom_X620_G50_TRT",
    "Result": 2598.53,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "0a5e94011727465e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G50_TRT",
    "Result": 17900.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "fb46b5ece6c74d16",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G50_TRT",
    "Result": 7503.01,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "5de939b6695f4081",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G50_TRT",
    "Result": 12183.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "14f92915bfbb4675",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G50_TRT",
    "Result": 5426.87,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "3c6ffa148a9546a7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G40_TRT",
    "Result": 11598.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "550657be9d734bdb",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G40_TRT",
    "Result": 5002.42,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "36c2871519d44be5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G40_TRT",
    "Result": 4551.79,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "395e9b32a1464ea2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G40_TRT",
    "Result": 2050.57,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "2e021524fc6f4047",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G50_TRT",
    "Result": 7453.21,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "ee13a46436654ea2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.02360747429393,
    "Accuracy_div_100": 0.91024,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G50_TRT",
    "Result": 4902.28,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b7a3fa55c9314f0e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L4x5_Custom_X620_G50_TRT",
    "Result": 4675.79,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (5x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 6458Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "bec439c6bb554e9c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.0333240761591,
    "Accuracy_div_100": 0.91033,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x5_Custom_X620_G50_TRT",
    "Result": 2798.93,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (5x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 6458Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "0ddac574461948ca",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2039469599852,
    "Accuracy_div_100": 0.90204,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config",
    "Result": 249.841,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "acb950b532fc4d64",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A40x8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 11499.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "a1555a198b564e63",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Inspur/results/NF5468M6_A40x8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.89196560959385,
    "Accuracy_div_100": 0.90892,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A40x8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 5251.59,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "79c9fc9451d84318",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Inspur/results/NF5468M6_A40x8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT_Triton/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT_Triton",
    "Result": 14797.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "073001da6b604b24",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT_Triton/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT_Triton/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT_Triton",
    "Result": 7553.12,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "95d8789c50af44f2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT_Triton/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_A30x4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5300G6_A30x4_TRT",
    "Result": 2719.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G6 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "0566b79b7ade45c0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5300G6_A30x4_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A2x2_TRT_Triton/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A2x2_TRT_Triton",
    "Result": 349.777,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4950 G6 (2x A2, TensorRT,Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 384,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "33f8c5045b964c46",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/A2x2_TRT_Triton/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_A30x4_TRT_Triton/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5300G6_A30x4_TRT_Triton",
    "Result": 6072.35,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G6 (4x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "382bdce5ca1e4743",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5300G6_A30x4_TRT_Triton/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT",
    "Result": 15098,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "55bdb2fe21e24157",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT",
    "Result": 6803.27,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "78db01e0871d493a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1093.37,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Rocky Linux release 9.0 (Blue Onyx)",
    "uid": "48ca9f7a1125472a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "dl385_q8_std-qaic-v1.8.3.7-aic100",
    "Result": 5376.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.15.0-60-generic #66~20.04.1-Ubuntu SMP Wed Jan 25 09:41:30 UTC 2023)",
    "uid": "832769c6ac5547a2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "dl385_q8_std-qaic-v1.8.3.7-aic100",
    "Result": 2573.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.15.0-60-generic #66~20.04.1-Ubuntu SMP Wed Jan 25 09:41:30 UTC 2023)",
    "uid": "bec65b2c248646a8",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1088.29,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ProLiant DL380a Gen11",
    "number_of_nodes": 2,
    "operating_system": "Red Hat Enterprise Linux 8.7",
    "uid": "03c6324aeb964e79",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Server",
    "version": "v3.0"
  }
]

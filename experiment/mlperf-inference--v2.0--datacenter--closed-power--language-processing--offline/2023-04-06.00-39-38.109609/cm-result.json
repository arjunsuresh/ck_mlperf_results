[
  {
    "Accuracy": 90.365426235864,
    "Accuracy_div_100": 0.90365,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q5e-qaic-v1.6.80-aic100",
    "Result": 3142.52,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "10ebfe4012174b77",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.365426235864,
    "Accuracy_div_100": 0.90365,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q5e-qaic-v1.6.80-aic100",
    "Result": null,
    "Result_Power": 438.98528417818784,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "30e02978c9d24f55",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "r282_z93_q5e-qaic-v1.6.80-aic100",
    "Result": 1448.92,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ec12ddb669b1454d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "r282_z93_q5e-qaic-v1.6.80-aic100",
    "Result": null,
    "Result_Power": 407.97801699716734,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ee1d3f2b156748b4",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.35738460861708,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q8_dc-qaic-v1.6.80-aic100",
    "Result": 5745.17,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "465b4ca3509c4f97",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.35738460861708,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q8_dc-qaic-v1.6.80-aic100",
    "Result": null,
    "Result_Power": 794.3025073746314,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "3d3eeb09ddbf44d3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "r282_z93_q8_dc-qaic-v1.6.80-aic100",
    "Result": 2906.84,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "d42a1de277ac4310",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "r282_z93_q8_dc-qaic-v1.6.80-aic100",
    "Result": null,
    "Result_Power": 740.2835866261397,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "54c4f8703ecb4bcc",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 19993.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "11f5f2f7ccbd4156",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": null,
    "Result_Power": 2361.50890868597,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b7ccd4c549b9413a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 9988.62,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "295864ca51a4450e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": null,
    "Result_Power": 2370.245529573592,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "22d4fc1f67034589",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "Result": 10827.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "95bc5f6ca92b4957",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "Result": null,
    "Result_Power": 1253.5281967213118,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3df2f43e2d3f4e8e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "Result": 5233.53,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "99ba4c9c42ff47ac",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "Result": null,
    "Result_Power": 1252.892709984151,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4e929127f86443dc",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 24793.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b1a33e29899642e0",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": null,
    "Result_Power": 3544.7035043804754,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "86423e3decb542d3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 11402.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6929ef36f89a431a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": null,
    "Result_Power": 3344.5726844584,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7dc5a97d5f454adf",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.39680495326127,
    "Accuracy_div_100": 0.90397,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_MaxQ",
    "Result": 20705.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "41d1eabda09e4335",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.39680495326127,
    "Accuracy_div_100": 0.90397,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_MaxQ",
    "Result": null,
    "Result_Power": 2806.7165477888743,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "65c4f82241e54954",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_MaxQ",
    "Result": 9857.47,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "731139ef59a14f87",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_MaxQ",
    "Result": null,
    "Result_Power": 2808.491666666664,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4fee238fa7fc49f4",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.40121712891282,
    "Accuracy_div_100": 0.90401,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_MaxQ",
    "Result": 10046.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8eb25a56b60d415d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.40121712891282,
    "Accuracy_div_100": 0.90401,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_MaxQ",
    "Result": null,
    "Result_Power": 1247.1512937595107,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3f3f65d14a764b9c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_MaxQ",
    "Result": 4991.01,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ef38a404cc95461f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_MaxQ",
    "Result": null,
    "Result_Power": 1252.6871601208431,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "15d8791b98254f1e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ",
    "Result": 23898.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Maximum GPU power is limitted to 275W with nvidia-smi command",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "200d6eae47fc4c34",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ",
    "Result": null,
    "Result_Power": 3419.12348484848,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Maximum GPU power is limitted to 275W with nvidia-smi command",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "32b87ad6245544a9",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ",
    "Result": 11883.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Maximum GPU power is limitted to 275W with nvidia-smi command",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "7ba46e8b1e78499a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ",
    "Result": null,
    "Result_Power": 3431.6585843373455,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Maximum GPU power is limitted to 275W with nvidia-smi command",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "42b6209b1fbe4661",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.6.80-aic100",
    "Result": 11305.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "00946ed29fbb4c9c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.6.80-aic100",
    "Result": null,
    "Result_Power": 1439.0219626168237,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ea62aa38bacc4a35",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.6.80-aic100",
    "Result": 5254.36,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ea78b89bf05b4d5b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.6.80-aic100",
    "Result": null,
    "Result_Power": 1294.427105666156,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "05bbb7ba2e2145a0",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.6.80-aic100",
    "Result": 5049.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "6fcaa2398445483a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.6.80-aic100",
    "Result": null,
    "Result_Power": 593.6849923430319,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "06a543de10da4e6e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.6.80-aic100",
    "Result": 2335.47,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "5161be40d6ce4e16",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.6.80-aic100",
    "Result": null,
    "Result_Power": 547.8050708215287,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "353639dd5b164c5c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.32079354407065,
    "Accuracy_div_100": 0.90321,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 244.643,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "d5262159b4fe429d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.32079354407065,
    "Accuracy_div_100": 0.90321,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": null,
    "Result_Power": 302.86136498516305,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "12fcb21d74f3474e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 119.573,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "dacda214289f406b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": null,
    "Result_Power": 293.02244343891437,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "14e11e07916544ac",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Offline",
    "version": "v2.0"
  }
]

[
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/aedk_25w-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "aedk_25w-qaic-v1.6.80-aic100",
    "Result": 361.091,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AI Development Kit",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Qualcomm Snapdragon 865",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 25W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS Linux release 8.0.1905 (kernel: 4.19.81 #1 SMP PREEMPT Thu Nov 4 04:01:15 UTC 2021)",
    "uid": "ca28b80b920842ba",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/aedk_25w-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 39.745757575757565,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/aedk_25w-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "aedk_25w-qaic-v1.6.80-aic100",
    "Result": 361.091,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AI Development Kit",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Qualcomm Snapdragon 865",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 25W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS Linux release 8.0.1905 (kernel: 4.19.81 #1 SMP PREEMPT Thu Nov 4 04:01:15 UTC 2021)",
    "uid": "ca28b80b920842ba",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/aedk_25w-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 39.745757575757565,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q8e-qaic-v1.6.80-aic100",
    "Result": 5049.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100, EE)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "b278439a57944dc0",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 591.1542725880552,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q8e-qaic-v1.6.80-aic100",
    "Result": 5049.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100, EE)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "b278439a57944dc0",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 591.1542725880552,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.254,
    "Accuracy_div_100": 0.90254,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Xavier_NX_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Xavier_NX_TRT_MaxQ",
    "Result": 48.2145,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Auvidea JNX30 Xavier NX (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "JetPack 4.6, TensorRT 8.0.1, CUDA 10.2",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 6,
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04",
    "uid": "aee78205b7e04e0d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Xavier_NX_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0",
    "Result_Power": 14.459448830409363,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.254,
    "Accuracy_div_100": 0.90254,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Xavier_NX_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Xavier_NX_TRT_MaxQ",
    "Result": 48.2145,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Auvidea JNX30 Xavier NX (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "JetPack 4.6, TensorRT 8.0.1, CUDA 10.2",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 6,
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04",
    "uid": "aee78205b7e04e0d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Xavier_NX_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0",
    "Result_Power": 14.459448830409363,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.104,
    "Accuracy_div_100": 0.90104,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 394.328,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "JetPack 5.0, TensorRT 8.4.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline scenario. DLA loadable for resnet50 in offline scenario generated using preview compiler. Private harness code to run loadables. git hash: f23b7273986f02d3136673e5d18558c9a9d63799",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "6558b5f6f64c4cb5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0",
    "Result_Power": 53.59359756097572,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.104,
    "Accuracy_div_100": 0.90104,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 394.328,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "JetPack 5.0, TensorRT 8.4.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline scenario. DLA loadable for resnet50 in offline scenario generated using preview compiler. Private harness code to run loadables. git hash: f23b7273986f02d3136673e5d18558c9a9d63799",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "6558b5f6f64c4cb5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0",
    "Result_Power": 53.59359756097572,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/aedk_15w-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "aedk_15w-qaic-v1.6.80-aic100",
    "Result": 179.471,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AI Development Kit",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2e",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Qualcomm Snapdragon 865",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 15W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS Linux release 8.0.1905 (kernel: 4.19.81 #1 SMP PREEMPT Thu Nov 4 04:01:15 UTC 2021)",
    "uid": "429a69d73c6041ff",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/aedk_15w-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 22.733176470588234,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/aedk_15w-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "aedk_15w-qaic-v1.6.80-aic100",
    "Result": 179.471,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AI Development Kit",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2e",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Qualcomm Snapdragon 865",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 15W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS Linux release 8.0.1905 (kernel: 4.19.81 #1 SMP PREEMPT Thu Nov 4 04:01:15 UTC 2021)",
    "uid": "429a69d73c6041ff",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/aedk_15w-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 22.733176470588234,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5e-qaic-v1.6.80-aic100",
    "Result": 3142.44,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100, EE)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "dd3b02556d684319",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 436.1131950844854,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5e-qaic-v1.6.80-aic100",
    "Result": 3142.44,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100, EE)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "dd3b02556d684319",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 436.1131950844854,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/gloria-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "gloria-qaic-v1.6.80-aic100",
    "Result": 230.295,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Foxconn Gloria",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2e",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Qualcomm Snapdragon 865",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 15W Accelerator TDP constraints; optional 5G and SSD modules not installed. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125 #1 SMP PREEMPT Tue Jan 11 22:26:27 UTC 2022)",
    "uid": "f43e8cf6c67642eb",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/gloria-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 23.718687203791454,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/gloria-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "gloria-qaic-v1.6.80-aic100",
    "Result": 230.295,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Foxconn Gloria",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2e",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Qualcomm Snapdragon 865",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 15W Accelerator TDP constraints; optional 5G and SSD modules not installed. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125 #1 SMP PREEMPT Tue Jan 11 22:26:27 UTC 2022)",
    "uid": "f43e8cf6c67642eb",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/gloria-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 23.718687203791454,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/aedk_20w-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "aedk_20w-qaic-v1.6.80-aic100",
    "Result": 315.894,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AI Development Kit",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Qualcomm Snapdragon 865",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 20W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS Linux release 8.0.1905 (kernel: 4.19.81 #1 SMP PREEMPT Thu Nov 4 04:01:15 UTC 2021)",
    "uid": "dfad635c7c3548b3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/aedk_20w-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 36.61333830104317,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/aedk_20w-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "aedk_20w-qaic-v1.6.80-aic100",
    "Result": 315.894,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AI Development Kit",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Qualcomm Snapdragon 865",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 20W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS Linux release 8.0.1905 (kernel: 4.19.81 #1 SMP PREEMPT Thu Nov 4 04:01:15 UTC 2021)",
    "uid": "dfad635c7c3548b3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/aedk_20w-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0",
    "Result_Power": 36.61333830104317,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_A30x1_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE2420_A30x1_TRT_MaxQ",
    "Result": 1670.45,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x A30, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ac3fb189602e4d88",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_A30x1_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0",
    "Result_Power": 300.30057766367116,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_A30x1_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE2420_A30x1_TRT_MaxQ",
    "Result": 1670.45,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x A30, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ac3fb189602e4d88",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_A30x1_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0",
    "Result_Power": 300.30057766367116,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36155137638657,
    "Accuracy_div_100": 0.90362,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Inspur",
    "Platform": "NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ",
    "Result": 5795.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NE5260M5 (2x A100-PCIe-80GB, TensorRT, MaxQ)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6258R",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8bc80d0a90114621",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0",
    "Result_Power": 813.3989515072083,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36155137638657,
    "Accuracy_div_100": 0.90362,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Inspur",
    "Platform": "NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ",
    "Result": 5795.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NE5260M5 (2x A100-PCIe-80GB, TensorRT, MaxQ)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6258R",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8bc80d0a90114621",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ/bert-99/Offline",
    "version": "v2.0",
    "Result_Power": 813.3989515072083,
    "Result_Power_Units": "Watts"
  }
]

[
  {
    "Accuracy": 90.32072989985656,
    "Accuracy_div_100": 0.90321,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_obert-mobilebert/SingleStream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert-mobilebert",
    "Organization": "NeuralMagic",
    "Platform": "nm80ci_icx_deepsparse",
    "Result": 5.443248,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NM80ci_ICX (2x Intel Xeon 8380, DeepSparse)",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.0.2, Python 3.9.13, GCC 11.2.0",
    "number_of_nodes": 1,
    "operating_system": " Ubuntu 22.04 LTS",
    "uid": "b92c56e084ca4645",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_obert-mobilebert/SingleStream",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.41656583679988,
    "Accuracy_div_100": 0.90417,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_prune-ofa-large/SingleStream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_prune-ofa-large",
    "Organization": "NeuralMagic",
    "Platform": "nm80ci_icx_deepsparse",
    "Result": 21.977228,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NM80ci_ICX (2x Intel Xeon 8380, DeepSparse)",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.0.2, Python 3.9.13, GCC 11.2.0",
    "number_of_nodes": 1,
    "operating_system": " Ubuntu 22.04 LTS",
    "uid": "b383bd730ad843ec",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_prune-ofa-large/SingleStream",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.21282641816266,
    "Accuracy_div_100": 0.90213,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_obert-large/SingleStream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert-large",
    "Organization": "NeuralMagic",
    "Platform": "nm80ci_icx_deepsparse",
    "Result": 16.887679,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NM80ci_ICX (2x Intel Xeon 8380, DeepSparse)",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.0.2, Python 3.9.13, GCC 11.2.0",
    "number_of_nodes": 1,
    "operating_system": " Ubuntu 22.04 LTS",
    "uid": "e6eabf8045e14414",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/NeuralMagic/results/nm80ci_icx_deepsparse/bert-99_obert-large/SingleStream",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.32506865037143,
    "Accuracy_div_100": 0.90325,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/chai/bert-99_obert_mobilebert_50sparse_qat/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert_mobilebert_50sparse_qat",
    "Organization": "Krai",
    "Platform": "chai",
    "Result": 28.823247,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A5000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "ONNX runtime v1.12 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1 LTS (Linux kernel: 5.19.0-32-generic #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2)",
    "uid": "9b832e8aa6124651",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Krai/results/chai/bert-99_obert_mobilebert_50sparse_qat/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.15897966063973,
    "Accuracy_div_100": 0.90159,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/chai/bert-99_obert_large_95sparse_qat/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert_large_95sparse_qat",
    "Organization": "Krai",
    "Platform": "chai",
    "Result": 125.587361,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A5000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "ONNX runtime v1.12 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1 LTS (Linux kernel: 5.19.0-32-generic #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2)",
    "uid": "658a36dc6ad84a96",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Krai/results/chai/bert-99_obert_large_95sparse_qat/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.67466754181211,
    "Accuracy_div_100": 0.90675,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/chai/bert-99_bert_large_huggingface_bast/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99_bert_large_huggingface_bast",
    "Organization": "Krai",
    "Platform": "chai",
    "Result": 15.227221,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A5000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "ONNX runtime v1.12 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1 LTS (Linux kernel: 5.19.0-32-generic #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2)",
    "uid": "54fa7bb4660042c1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Krai/results/chai/bert-99_bert_large_huggingface_bast/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.0251156865308,
    "Accuracy_div_100": 0.91025,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_standard_4_nvidia_t4-reference-gpu-onnxruntime-v1.14.0-default_config",
    "Result": 80.878297,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Google cloud instance n1-standard-4 (Debian 10)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Debian 10 (linux-4.19.0-23-cloud-amd64-glibc2.28)",
    "uid": "6a6d3fa42e7d4f14",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 89.961820272891,
    "Accuracy_div_100": 0.89962,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-cpu-onnxruntime-v1.13.1-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_standard_4_nvidia_t4-reference-cpu-onnxruntime-v1.13.1-default_config",
    "Result": 952.839522,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Google cloud instance n1-standard-4",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.13.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Debian 10 (linux-4.19.0-23-cloud-amd64-glibc2.28)",
    "uid": "06147333fd3a42a1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-cpu-onnxruntime-v1.13.1-default_config/bert-99/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.81319248746797,
    "Accuracy_div_100": 0.90813,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_highmem_4_nvidia_k80-reference-gpu-onnxruntime-v1.14.0-default_config",
    "Result": 151.153289,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Google cloud instance n1-highmem-4 with Nvidia K80 GPU",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "Nvidia Tesla K80",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1029-gcp-glibc2.35)",
    "uid": "ddca1b419dda452c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.70178690362079,
    "Accuracy_div_100": 0.90702,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-tensorflow-v2.11.0-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_highmem_4_nvidia_k80-reference-gpu-tensorflow-v2.11.0-default_config",
    "Result": 193.78854,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Google cloud instance n1-highmem-4 with Nvidia K80 GPU",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "Nvidia Tesla K80",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1029-gcp-glibc2.35)",
    "uid": "92e43ffc8ed54091",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-tensorflow-v2.11.0-default_config/bert-99/singlestream",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.82662393091758,
    "Accuracy_div_100": 0.90827,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-pytorch-v1.13.1-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_standard_4_nvidia_t4-reference-gpu-pytorch-v1.13.1-default_config",
    "Result": 95.731032,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Google cloud instance n1-standard-4",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch v1.13.1 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Debian 10 (linux-4.19.0-23-cloud-amd64-glibc2.28)",
    "uid": "22ae25127e054f6a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-pytorch-v1.13.1-default_config/bert-99/singlestream",
    "version": "v3.0"
  }
]

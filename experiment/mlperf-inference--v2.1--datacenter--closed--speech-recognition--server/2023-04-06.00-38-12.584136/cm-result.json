[
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Supermicro",
    "Platform": "AS-4124GS-TNR_8_A100-PCIe-80GB_TRT",
    "Result": 90004.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4124GS-TNR (8xA100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8a0ac02a72c94d04",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 1347.28,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c96832d4a6c541b3",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 104020,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4f5bc9f3908a4d7c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55902049651627,
    "Accuracy_div_100": 0.92559,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-SXM-80GBx1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "H100-SXM-80GBx1_TRT",
    "Result": 21487.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.0, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7252 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Private git branch used to produce all NVIDIA H100 results. The git hash of the private branch is 35fc4b9a7758edc6063bb3a4ba4bfa94ce7aa9e1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7dd059e3156c4ea4",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/H100-SXM-80GBx1_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 90004.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f82ea01306dc4712",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.54549144287357,
    "Accuracy_div_100": 0.92545,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000_A2x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000_A2x8_TRT",
    "Result": 7394.06,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUS ESC4000-E10S (8x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": " Intel(R) Xeon(R) Platinum 8352M 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "cce24221c8714081",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/ESC4000_A2x8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ASUSTeK",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 98511.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUS ESC8000A-E11 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "459ca4265568445d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT",
    "Result": 104020,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "c50f79a3f53b40e5",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.54549144287357,
    "Accuracy_div_100": 0.92545,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NV72ads_A10_v5_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "NV72ads_A10_v5_TRT",
    "Result": 6993.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NV72ads_A10_v5 (2x NVIDIA A10-24Q, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A10-24Q",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2.3, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 74F3 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "469b855920bc4b76",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NV72ads_A10_v5_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 46396.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "7640aca502fa40e8",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Lenovo",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 90004.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo SR670v2 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "eedb1c2922594d25",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Lenovo/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Lenovo",
    "Platform": "A100_SXM_80GBx4_TRT",
    "Result": 51997.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo SR670v2 (4x A100-SXM-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d7ccec3bc19545cd",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Lenovo/results/A100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 49592.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "0e723448cd8246aa",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT",
    "Result": 55197.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "845e31879fcd49cf",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "GIGABYTE",
    "Platform": "G492-ID0_A100-SXM-80GBx8_TRT",
    "Result": 108514,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "G492-ID0 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "d3e611a295df4251",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "A100_SXM4_80GBx8_Custom_TRT",
    "Result": 109913,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X660G45L (8x A100-SXM4-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP:500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4b267d66f0c34804",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.53872691605223,
    "Accuracy_div_100": 0.92539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A2x5_R4900G5_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "A2x5_R4900G5_TRT",
    "Result": 3996.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5(5x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "dbe9d971b619485b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A2x5_R4900G5_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A30x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5300G5_A30x8_TRT",
    "Result": 39396.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "814623ca3a154181",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A30x8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT",
    "Result": 12994.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "a55797982e2f4a22",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5500G5_Intel_A100_A100-SXM-80GBx8_TRT",
    "Result": 107914,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5500 G5 Intel (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8378A",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "eb8c8d2562df4e7f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx3_R4900G5_TRT",
    "Result": 33289.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5(3x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "24bc39fff6f448b7",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5500G5_AMD_A100_A100-SXM-80GBx8_TRT",
    "Result": 107515,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5500 G5 AMD (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7773X",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "1a96abc15e1c4b9e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_SXM_80GBx4_TRT",
    "Result": 44998.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5(4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "9810a135f47e4303",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5567656542425,
    "Accuracy_div_100": 0.92557,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_PCIE_80GBX4_TRT",
    "Result": 47797.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.5",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "2a13ca4d59474a2c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-40GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-40GBx4_TRT",
    "Result": 47997.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Apollo 6500 Gen10+ (645d - 4x A100 SXM 40GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7702",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "f9879109e10c4114",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-40GBx4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 1347.28,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Apollo 6500 Gen10+ (675d - 8x A100-SXM-80GB-MIG-1x1g.10gb), TensorRT",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "b1cf659ac7c64c3b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT/rnnt/Server",
    "version": "v2.1"
  }
]

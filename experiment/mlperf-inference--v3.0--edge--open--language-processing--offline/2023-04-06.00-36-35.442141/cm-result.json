[
  {
    "Accuracy": 90.32506865037143,
    "Accuracy_div_100": 0.90325,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/chai/bert-99_obert_mobilebert_50sparse_qat/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert_mobilebert_50sparse_qat",
    "Organization": "Krai",
    "Platform": "chai",
    "Result": 36.9691,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA RTX A5000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "ONNX runtime v1.12 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1 LTS (Linux kernel: 5.19.0-32-generic #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2)",
    "uid": "a5339cfebb064493",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Krai/results/chai/bert-99_obert_mobilebert_50sparse_qat/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.15897966063973,
    "Accuracy_div_100": 0.90159,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/chai/bert-99_obert_large_95sparse_qat/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert_large_95sparse_qat",
    "Organization": "Krai",
    "Platform": "chai",
    "Result": 8.17719,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA RTX A5000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "ONNX runtime v1.12 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1 LTS (Linux kernel: 5.19.0-32-generic #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2)",
    "uid": "178da63e63f74a84",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Krai/results/chai/bert-99_obert_large_95sparse_qat/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.67466754181211,
    "Accuracy_div_100": 0.90675,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/chai/bert-99_bert_large_huggingface_bast/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_bert_large_huggingface_bast",
    "Organization": "Krai",
    "Platform": "chai",
    "Result": 66.0495,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA RTX A5000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "ONNX runtime v1.12 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1 LTS (Linux kernel: 5.19.0-32-generic #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2)",
    "uid": "e656912c78db4a54",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Krai/results/chai/bert-99_bert_large_huggingface_bast/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 87.81864061182722,
    "Accuracy_div_100": 0.87819,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/amd_zen4_workstation-reference-cpu-deepsparse-v1.4.0-default_config/bert-base/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base",
    "Organization": "cTuning",
    "Platform": "amd_zen4_workstation-reference-cpu-deepsparse-v1.4.0-default_config",
    "Result": 207.282,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AMD Ryzen Zen4 workstation",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Deepsparse v1.4.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Result donated by GATE Overflow Educational Foundation. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-32-generic-glibc2.35)",
    "uid": "16e806b8587e414e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/amd_zen4_workstation-reference-cpu-deepsparse-v1.4.0-default_config/bert-base/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.44,
    "Accuracy_div_100": 0.9044,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.64_exp2/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.64_exp2",
    "Result": 449.122,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Experiment repeated. Batch size for bert-99 fixed to 64. Powered by MLCommons Collective Mind framework (CK2).",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.65-tegra-glibc2.31)",
    "uid": "4a72eccaae9c4ee5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.64_exp2/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_standard_4_nvidia_t4-reference-gpu-onnxruntime-v1.14.0-default_config",
    "Result": 12.5113,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Google cloud instance n1-standard-4 (Debian 10)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Debian 10 (linux-4.19.0-23-cloud-amd64-glibc2.28)",
    "uid": "d291d3de630f4ead",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.441,
    "Accuracy_div_100": 0.90441,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.512_exp2/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.512_exp2",
    "Result": 437.046,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Experiment repeated. Batch size for bert-99 fixed to 512. Powered by MLCommons Collective Mind framework (CK2).",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.65-tegra-glibc2.31)",
    "uid": "e726a03e4dea4518",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.512_exp2/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.44,
    "Accuracy_div_100": 0.9044,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.128_exp2/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.128_exp2",
    "Result": 453.578,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Experiment repeated. Batch size for bert-99 fixed to 128. Powered by MLCommons Collective Mind framework (CK2).",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.65-tegra-glibc2.31)",
    "uid": "38e41823fb854e1a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.128_exp2/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.44,
    "Accuracy_div_100": 0.9044,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.128/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.128",
    "Result": 454.451,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Batch size for bert-99 fixed to 128. Powered by MLCommons Collective Mind framework (CK2).",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.65-tegra-glibc2.31)",
    "uid": "fbd8f1042b3a4b5a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.128/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.441,
    "Accuracy_div_100": 0.90441,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.256/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.256",
    "Result": 441.855,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Batch size for bert-99 fixed to 256. Powered by MLCommons Collective Mind framework (CK2).",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.65-tegra-glibc2.31)",
    "uid": "b5e99a1d094144dd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.256/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.441,
    "Accuracy_div_100": 0.90441,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.512/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.512",
    "Result": 431.806,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Batch size for bert-99 fixed to 512. Powered by MLCommons Collective Mind framework (CK2).",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.65-tegra-glibc2.31)",
    "uid": "a67c03d52d664de5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.512/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.441,
    "Accuracy_div_100": 0.90441,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.256_exp2/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.256_exp2",
    "Result": 439.24,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Experiment repeated. Batch size for bert-99 fixed to 256. Powered by MLCommons Collective Mind framework (CK2).",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.65-tegra-glibc2.31)",
    "uid": "8a3d2eb22a5b4df6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.256_exp2/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_highmem_4_nvidia_k80-reference-gpu-onnxruntime-v1.14.0-default_config",
    "Result": 6.72796,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Google cloud instance n1-highmem-4 with Nvidia K80 GPU",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Nvidia Tesla K80",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1029-gcp-glibc2.35)",
    "uid": "125dd4461b3b4e16",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87410716832628,
    "Accuracy_div_100": 0.90874,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-tensorflow-v2.11.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_highmem_4_nvidia_k80-reference-gpu-tensorflow-v2.11.0-default_config",
    "Result": 5.12931,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Google cloud instance n1-highmem-4 with Nvidia K80 GPU",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Nvidia Tesla K80",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1029-gcp-glibc2.35)",
    "uid": "8d044556e18d41ae",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_highmem_4_nvidia_k80-reference-gpu-tensorflow-v2.11.0-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.44,
    "Accuracy_div_100": 0.9044,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.64/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.64",
    "Result": 445.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Batch size for bert-99 fixed to 54. Powered by MLCommons Collective Mind framework (CK2).",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.65-tegra-glibc2.31)",
    "uid": "f22177f90daa4ae0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/nvidia_orin-nvidia_original-gpu-tensorrt-v8.5.2.2-batch_size.64/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_graviton_m7g.2xlarge-reference-cpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_graviton_m7g.2xlarge-reference-cpu-onnxruntime-v1.14.0-default_config",
    "Result": 1.2339,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance m7g.2xlarge (graviton)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "8605fdfc95cc4bf4",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_graviton_m7g.2xlarge-reference-cpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "gcp_n1_standard_4_nvidia_t4-reference-gpu-pytorch-v1.13.1-default_config",
    "Result": 10.6034,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Google cloud instance n1-standard-4",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch v1.13.1 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": " Result taken by Grigori Fursin. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Debian 10 (linux-4.19.0-23-cloud-amd64-glibc2.28)",
    "uid": "b0e75720fc234c46",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/gcp_n1_standard_4_nvidia_t4-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "version": "v3.0"
  }
]

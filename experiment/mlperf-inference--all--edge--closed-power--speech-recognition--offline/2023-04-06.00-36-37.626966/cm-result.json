[
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Xavier_NX_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Xavier_NX_TRT_MaxQ",
    "Result": 195.611,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Auvidea JNX30 Xavier NX (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "JetPack 4.6, TensorRT 8.0.1, CUDA 10.2",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 6,
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04",
    "uid": "3c3212a448eb40b0",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Xavier_NX_TRT_MaxQ/rnnt/Offline",
    "version": "v2.0",
    "Result_Power": 16.37933018867925,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Xavier_NX_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Xavier_NX_TRT_MaxQ",
    "Result": 195.611,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Auvidea JNX30 Xavier NX (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "JetPack 4.6, TensorRT 8.0.1, CUDA 10.2",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 6,
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04",
    "uid": "3c3212a448eb40b0",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Xavier_NX_TRT_MaxQ/rnnt/Offline",
    "version": "v2.0",
    "Result_Power": 16.37933018867925,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 791.251,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "JetPack 5.0, TensorRT 8.4.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline scenario. DLA loadable for resnet50 in offline scenario generated using preview compiler. Private harness code to run loadables. git hash: f23b7273986f02d3136673e5d18558c9a9d63799",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "ff9c7baadb864d9b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "version": "v2.0",
    "Result_Power": 42.07170506912442,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 791.251,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "JetPack 5.0, TensorRT 8.4.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline scenario. DLA loadable for resnet50 in offline scenario generated using preview compiler. Private harness code to run loadables. git hash: f23b7273986f02d3136673e5d18558c9a9d63799",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "ff9c7baadb864d9b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "version": "v2.0",
    "Result_Power": 42.07170506912442,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_A30x1_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE2420_A30x1_TRT_MaxQ",
    "Result": 5612.13,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x A30, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "66fa4493f09a42ac",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_A30x1_TRT_MaxQ/rnnt/Offline",
    "version": "v2.0",
    "Result_Power": 291.79041514041495,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_A30x1_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE2420_A30x1_TRT_MaxQ",
    "Result": 5612.13,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x A30, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "66fa4493f09a42ac",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_A30x1_TRT_MaxQ/rnnt/Offline",
    "version": "v2.0",
    "Result_Power": 291.79041514041495,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Inspur",
    "Platform": "NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ",
    "Result": 24566.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NE5260M5 (2x A100-PCIe-80GB, TensorRT, MaxQ)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6258R",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "16832248696e493d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ/rnnt/Offline",
    "version": "v2.0",
    "Result_Power": 830.4948965517241,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Inspur",
    "Platform": "NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ",
    "Result": 24566.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NE5260M5 (2x A100-PCIe-80GB, TensorRT, MaxQ)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6258R",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "16832248696e493d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ/rnnt/Offline",
    "version": "v2.0",
    "Result_Power": 830.4948965517241,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 716.007,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "22.08 Jetson CUDA-X AI Developer Preview, TensorRT 8.5.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "daa68132e5b94ec5",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "version": "v2.1",
    "Result_Power": 25.63559722222222,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 716.007,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "22.08 Jetson CUDA-X AI Developer Preview, TensorRT 8.5.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "daa68132e5b94ec5",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "version": "v2.1",
    "Result_Power": 25.63559722222222,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 688.09,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "23.02 Jetson CUDA-X AI Developer Preview, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "6e2b20932b2c4802",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "version": "v3.0",
    "Result_Power": 24.22208277703603,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 688.09,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "23.02 Jetson CUDA-X AI Developer Preview, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "6e2b20932b2c4802",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/Offline",
    "version": "v3.0",
    "Result_Power": 24.22208277703603,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 3902.39,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "89071b1df815447f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/Offline",
    "version": "v3.0",
    "Result_Power": 645.6733383915025,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 3902.39,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "89071b1df815447f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/Offline",
    "version": "v3.0",
    "Result_Power": 645.6733383915025,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.53647207377844,
    "Accuracy_div_100": 0.92536,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_MaxQ_A2x1_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR4520c_MaxQ_A2x1_TRT_MaxQ",
    "Result": 1050.09,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR4520c (1x A2, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "f2902445c8f3426c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_MaxQ_A2x1_TRT_MaxQ/rnnt/Offline",
    "version": "v3.0",
    "Result_Power": 186.66621023513162,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.53647207377844,
    "Accuracy_div_100": 0.92536,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_MaxQ_A2x1_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR4520c_MaxQ_A2x1_TRT_MaxQ",
    "Result": 1050.09,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR4520c (1x A2, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "f2902445c8f3426c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_MaxQ_A2x1_TRT_MaxQ/rnnt/Offline",
    "version": "v3.0",
    "Result_Power": 186.66621023513162,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/cTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/rnnt/offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "cTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config",
    "Result": 15281.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AMD Ryzen Zen4 workstation with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Result donated by GATE Overflow Educational Foundation. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-32-generic-glibc2.35)",
    "uid": "8ac45cba4c6547ee",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/cTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/rnnt/offline",
    "version": "v3.0",
    "Result_Power": 599.4694214876035,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/cTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/rnnt/offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "cTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config",
    "Result": 15281.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AMD Ryzen Zen4 workstation with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Result donated by GATE Overflow Educational Foundation. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-32-generic-glibc2.35)",
    "uid": "8ac45cba4c6547ee",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/cTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/rnnt/offline",
    "version": "v3.0",
    "Result_Power": 599.4694214876035,
    "Result_Power_Units": "Watts"
  }
]
